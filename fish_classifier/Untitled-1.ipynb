{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fish classifier\n",
    "\n",
    "Author: Łukasz Szarecki \n",
    "\n",
    "Dataset: https://www.kaggle.com/aungpyaeap/fish-market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Uploading data to pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Species  Weight  Length1  Length2  Length3   Height   Width\n",
      "0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
      "1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
      "2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
      "3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
      "4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "fish_df = pd.read_csv(\"Fish.csv\")\n",
    "print(fish_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We have to mix data because there are sorted.\n",
    "3. Preapering training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Species  Weight  Length1  Length2  Length3   Height   Width\n",
      "0    Pike   200.0     30.0     32.3     34.8   5.5680  3.3756\n",
      "1   Perch   130.0     20.0     22.0     23.5   6.1100  3.5250\n",
      "2   Bream   714.0     32.7     36.0     41.5  16.5170  5.8515\n",
      "3   Bream   620.0     31.5     34.5     39.7  15.5227  5.2801\n",
      "4    Pike   540.0     40.1     43.0     45.8   7.7860  5.1296\n",
      "There are 159 samples\n"
     ]
    }
   ],
   "source": [
    "#sorting dataset\n",
    "fish_df = fish_df.sample(frac=1)\n",
    "#corect indexing\n",
    "fish_df = fish_df.reset_index(drop=True)\n",
    "print(fish_df.head())\n",
    "print(f'There are {len(fish_df)} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Input and output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 6)\n",
      "(159,)\n"
     ]
    }
   ],
   "source": [
    "#input\n",
    "X = np.array(fish_df.iloc[:, 1::])\n",
    "print(X.shape)\n",
    "#output\n",
    "Y = (fish_df.iloc[:,0])\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder class\n",
    "\n",
    "3. Each fish will have its own identifier\n",
    "* fit() - create connection between identifiers and fish names\n",
    "* transform() - fish name (str) to id (int)\n",
    "* inverse_transform() - id (int) to fish name (str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self):\n",
    "        self.names = [] #to not store duplicated names\n",
    "        self.num_classes = 0 #number of all classes\n",
    "    def fit(self, y):\n",
    "        for sample in y:\n",
    "            if sample not in self.names:\n",
    "                self.names.append(sample)\n",
    "        self.num_classes = len(self.names)\n",
    "    def transform(self, y):\n",
    "        encoded_samples = np.zeros(len(y))\n",
    "        for index,sample in enumerate(y):\n",
    "            encoded_samples[index] = self.names.index(sample)\n",
    "        return encoded_samples\n",
    "    def inverse_transform(self, encoded_y):\n",
    "        samples = []\n",
    "        for sample in encoded_y:\n",
    "            samples.append(self.names[int(sample)])\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pike', 'Perch', 'Bream', 'Smelt', 'Whitefish', 'Parkki', 'Roach']\n",
      "7\n",
      "['Pike', 'Smelt', 'Perch', 'Pike', 'Pike', 'Bream', 'Bream', 'Roach']\n"
     ]
    }
   ],
   "source": [
    "#tests\n",
    "encoder = Encoder()\n",
    "encoder.fit(Y)\n",
    "print(encoder.names)\n",
    "print(encoder.num_classes) \n",
    "\n",
    "test_list = ['Pike', 'Smelt', 'Perch', 'Pike', 'Pike', 'Bream', 'Bream', 'Roach']\n",
    "encoded_num_test = encoder.transform(test_list)\n",
    "print(encoder.inverse_transform(encoded_num_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Encoding dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 2. 0. 3. 2. 1. 4. 3. 1. 1. 5. 2. 1. 1. 6. 3. 5. 6. 4. 6. 1. 3.\n",
      " 1. 5. 5. 1. 6. 2. 1. 1. 1. 1. 1. 1. 4. 6. 2. 2. 0. 6. 6. 1. 1. 2. 6. 6.\n",
      " 5. 4. 5. 3. 1. 0. 2. 1. 5. 1. 3. 1. 1. 1. 2. 1. 1. 1. 1. 6. 2. 0. 1. 1.\n",
      " 6. 2. 2. 2. 1. 5. 0. 0. 2. 1. 2. 1. 1. 6. 4. 3. 1. 1. 1. 2. 2. 1. 6. 2.\n",
      " 1. 4. 1. 0. 1. 0. 6. 6. 2. 1. 2. 0. 6. 1. 3. 3. 0. 6. 2. 2. 0. 1. 0. 1.\n",
      " 2. 0. 5. 0. 6. 5. 1. 2. 1. 2. 6. 1. 3. 2. 2. 1. 1. 0. 3. 6. 2. 0. 1. 2.\n",
      " 1. 3. 1. 2. 1. 1. 5. 3. 2. 2. 2. 1. 1. 3. 2.]\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder()\n",
    "encoder.fit(Y)\n",
    "encoded_y = encoder.transform(Y)\n",
    "print(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.14401849e-14, -1.07251734e-15,  9.20577381e-15,  9.20577381e-15,\n",
       "        3.35161668e-16, -4.24538113e-16])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw = X - np.mean(X, axis=0)\n",
    "qw\n",
    "np.mean(qw, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling - Normalization\n",
    "\n",
    "* test fraction - percentage of test data\n",
    "* xte - test data\n",
    "* xtr - training data\n",
    "\n",
    "xtr ->\n",
    "* mean = 0\n",
    "* standard deviation = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, x,y,test_fraction=0.05):\n",
    "        test_samples = int(test_fraction * y.size)\n",
    "        self.xte = x[:test_samples,:]   \n",
    "        self.xtr = x[test_samples:,:]   \n",
    "        self.yte = y[:test_samples]   \n",
    "        self.ytr = y[test_samples:]\n",
    "        self.mean = np.mean(self.xtr, axis=0)\n",
    "        self.std = np.std(self.xtr, axis=0)#standard deviation\n",
    "        self.xtr = self.normalize(self.xtr)\n",
    "        self.xte = self.normalize(self.xte)\n",
    "\n",
    "    def normalize(self, x):\n",
    "        x_temp = (x - self.mean)/self.std\n",
    "        return x_temp\n",
    "        \n",
    "fish_ds = Dataset(X,encoded_y,0.15)\n",
    "# fish_ds.xte \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(fish_ds.yte)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers models\n",
    "\n",
    "- Random Classifier\n",
    "- KNN - K - Nearest Neighbors Algorithm\n",
    "- Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classfier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, xtr, ytr):\n",
    "        pass\n",
    "    def predict(self, x):\n",
    "        pass\n",
    "    def evaluate(self, xte, yte):\n",
    "        ypred = self.predict(xte)\n",
    "        print(yte.astype(int))\n",
    "        print(ypred)\n",
    "        acc = np.sum(ypred == yte) / yte.size #Accuracy\n",
    "        return acc\n",
    "\n",
    "# Baseline (method)\n",
    "class RandomClassifier(Classfier):\n",
    "    #expected accuracy = 1/7\n",
    "    def fit(self, xtr, ytr):\n",
    "        self.num_classes = int(np.max(ytr) + 1)\n",
    "    def predict(self, x):\n",
    "        return np.random.choice(self.num_classes, x.shape[0])\n",
    "\n",
    "class KNNClassifier(Classfier):\n",
    "    def __init__(self, k=3):   #hyperparameters\n",
    "        self.k = k\n",
    "    def fit(self, xtr, ytr):\n",
    "        self.xtr = xtr\n",
    "        self.ytr = ytr\n",
    "    def predict(self, x):\n",
    "        num_samples =  x.shape[0]\n",
    "        ypred = np.zeros(num_samples, dtype=int)\n",
    "        for i in range(num_samples):\n",
    "            distance = np.sum((self.xtr - x[i, :])**2, axis=1)\n",
    "            order = np.argsort(distance)\n",
    "            knn_label = self.ytr[order][:self.k].astype(int)\n",
    "            print(f'knn labels {knn_label}')\n",
    "            binc = np.bincount(knn_label)\n",
    "            print(f'Bin count {binc}')\n",
    "            print(f'Y pred {binc.argmax()}')\n",
    "            ypred[i] = binc.argmax()    #argument which store max value\n",
    "        return ypred    \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 2 0 3 2 1 4 3 1 1 5 2 1 1 6 3 5 6 4 6 1]\n",
      "[5 1 6 0 3 1 0 5 2 2 5 5 5 5 6 3 2 2 0 6 2 6 2]\n",
      "0.17391304347826086\n",
      "knn labels [0 0 0]\n",
      "Bin count [3]\n",
      "Y pred 0\n",
      "knn labels [1 1 1]\n",
      "Bin count [0 3]\n",
      "Y pred 1\n",
      "knn labels [2 2 2]\n",
      "Bin count [0 0 3]\n",
      "Y pred 2\n",
      "knn labels [2 2 2]\n",
      "Bin count [0 0 3]\n",
      "Y pred 2\n",
      "knn labels [0 0 0]\n",
      "Bin count [3]\n",
      "Y pred 0\n",
      "knn labels [3 3 3]\n",
      "Bin count [0 0 0 3]\n",
      "Y pred 3\n",
      "knn labels [2 2 2]\n",
      "Bin count [0 0 3]\n",
      "Y pred 2\n",
      "knn labels [1 1 1]\n",
      "Bin count [0 3]\n",
      "Y pred 1\n",
      "knn labels [1 1 1]\n",
      "Bin count [0 3]\n",
      "Y pred 1\n",
      "knn labels [3 3 3]\n",
      "Bin count [0 0 0 3]\n",
      "Y pred 3\n",
      "knn labels [6 6 6]\n",
      "Bin count [0 0 0 0 0 0 3]\n",
      "Y pred 6\n",
      "knn labels [1 6 1]\n",
      "Bin count [0 2 0 0 0 0 1]\n",
      "Y pred 1\n",
      "knn labels [5 5 5]\n",
      "Bin count [0 0 0 0 0 3]\n",
      "Y pred 5\n",
      "knn labels [2 2 2]\n",
      "Bin count [0 0 3]\n",
      "Y pred 2\n",
      "knn labels [1 6 1]\n",
      "Bin count [0 2 0 0 0 0 1]\n",
      "Y pred 1\n",
      "knn labels [1 1 1]\n",
      "Bin count [0 3]\n",
      "Y pred 1\n",
      "knn labels [6 1 1]\n",
      "Bin count [0 2 0 0 0 0 1]\n",
      "Y pred 1\n",
      "knn labels [3 3 3]\n",
      "Bin count [0 0 0 3]\n",
      "Y pred 3\n",
      "knn labels [5 2 2]\n",
      "Bin count [0 0 2 0 0 1]\n",
      "Y pred 2\n",
      "knn labels [6 1 1]\n",
      "Bin count [0 2 0 0 0 0 1]\n",
      "Y pred 1\n",
      "knn labels [4 6 1]\n",
      "Bin count [0 1 0 0 1 0 1]\n",
      "Y pred 1\n",
      "knn labels [1 1 6]\n",
      "Bin count [0 2 0 0 0 0 1]\n",
      "Y pred 1\n",
      "knn labels [1 1 1]\n",
      "Bin count [0 3]\n",
      "Y pred 1\n",
      "[0 1 2 2 0 3 2 1 4 3 1 1 5 2 1 1 6 3 5 6 4 6 1]\n",
      "[0 1 2 2 0 3 2 1 1 3 6 1 5 2 1 1 1 3 2 1 1 1 1]\n",
      "0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "random_classifier = RandomClassifier()\n",
    "random_classifier.fit(fish_ds.xtr, fish_ds.ytr)\n",
    "randow_acc = random_classifier.evaluate(fish_ds.xte, fish_ds.yte)\n",
    "print(randow_acc)\n",
    "\n",
    "knn_classifier = KNNClassifier()\n",
    "knn_classifier.fit(fish_ds.xtr, fish_ds.ytr)\n",
    "knn_acc = knn_classifier.evaluate(fish_ds.xte, fish_ds.yte)\n",
    "print(knn_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note [PL]**\n",
    "Każdy model w uczeniu maszynowym ma parametry. Jedne mają ich więcej drugie mniej. Jeśli parametr wyliczany jest samodzielnie przez algorytm podczas uczenia nazywamy go po prostu parametrem. Przykładem mogą być wagi w sieciach neuronowych.\n",
    "\n",
    "Natomiast jeśli parametr podawany jest przez użytkownika, który używa algorytmu, wówczas nazywamy go hiperparametrem"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5d8d3d050c10ab3dcb6699cc248e53317db60ba2858504a06e019b80fca7572"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
