{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fish classifier\n",
    "\n",
    "Author: Åukasz Szarecki \n",
    "\n",
    "Dataset: https://www.kaggle.com/aungpyaeap/fish-market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Uploading data to pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Species  Weight  Length1  Length2  Length3   Height   Width\n",
      "0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
      "1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
      "2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
      "3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
      "4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "fish_df = pd.read_csv(\"Fish.csv\")\n",
    "print(fish_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We have to mix data because there are sorted.\n",
    "3. Preapering training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Species  Weight  Length1  Length2  Length3   Height   Width\n",
      "0   Perch   556.0     32.0     34.5     36.5  10.2565  6.3875\n",
      "1   Perch    51.5     15.0     16.2     17.2   4.5924  2.6316\n",
      "2   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
      "3   Perch    32.0     12.5     13.7     14.7   3.5280  1.9992\n",
      "4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340\n",
      "There are 159 samples\n"
     ]
    }
   ],
   "source": [
    "#sorting dataset\n",
    "fish_df = fish_df.sample(frac=1)\n",
    "#corect indexing\n",
    "fish_df = fish_df.reset_index(drop=True)\n",
    "print(fish_df.head())\n",
    "print(f'There are {len(fish_df)} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Input and output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 6)\n",
      "(159,)\n"
     ]
    }
   ],
   "source": [
    "#input\n",
    "X = np.array(fish_df.iloc[:, 1::])\n",
    "print(X.shape)\n",
    "#output\n",
    "Y = (fish_df.iloc[:,0])\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder class\n",
    "\n",
    "3. Each fish will have its own identifier\n",
    "* fit() - create connection between identifiers and fish names\n",
    "* transform() - fish name (str) to id (int)\n",
    "* inverse_transform() - id (int) to fish name (str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self):\n",
    "        self.names = [] #to not store duplicated names\n",
    "        self.num_classes = 0 #number of all classes\n",
    "    def fit(self, y):\n",
    "        for sample in y:\n",
    "            if sample not in self.names:\n",
    "                self.names.append(sample)\n",
    "        self.num_classes = len(self.names)\n",
    "    def transform(self, y):\n",
    "        encoded_samples = np.zeros(len(y))\n",
    "        for index,sample in enumerate(y):\n",
    "            encoded_samples[index] = self.names.index(sample)\n",
    "        return encoded_samples\n",
    "    def inverse_transform(self, encoded_y):\n",
    "        samples = []\n",
    "        for sample in encoded_y:\n",
    "            samples.append(self.names[int(sample)])\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Perch', 'Bream', 'Pike', 'Smelt', 'Roach', 'Whitefish', 'Parkki']\n",
      "7\n",
      "['Pike', 'Smelt', 'Perch', 'Pike', 'Pike', 'Bream', 'Bream', 'Roach']\n"
     ]
    }
   ],
   "source": [
    "#tests\n",
    "encoder = Encoder()\n",
    "encoder.fit(Y)\n",
    "print(encoder.names)\n",
    "print(encoder.num_classes) \n",
    "\n",
    "test_list = ['Pike', 'Smelt', 'Perch', 'Pike', 'Pike', 'Bream', 'Bream', 'Roach']\n",
    "encoded_num_test = encoder.transform(test_list)\n",
    "print(encoder.inverse_transform(encoded_num_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Encoding dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 1. 2. 2. 0. 0. 0. 1. 2. 3. 1. 2. 0. 4. 4. 0. 1. 0. 0. 2. 5.\n",
      " 1. 0. 1. 6. 1. 0. 6. 3. 0. 0. 5. 0. 0. 0. 2. 1. 1. 2. 4. 0. 6. 0. 4. 4.\n",
      " 1. 1. 0. 1. 0. 6. 6. 1. 2. 6. 6. 0. 0. 0. 3. 4. 5. 3. 4. 1. 1. 2. 2. 4.\n",
      " 2. 0. 1. 3. 0. 0. 4. 0. 0. 2. 2. 0. 0. 2. 4. 3. 0. 4. 3. 6. 0. 3. 1. 4.\n",
      " 1. 1. 1. 0. 0. 1. 3. 1. 4. 1. 6. 1. 0. 1. 5. 2. 0. 0. 0. 0. 5. 1. 0. 0.\n",
      " 6. 1. 1. 0. 4. 3. 0. 1. 3. 5. 0. 0. 0. 0. 1. 3. 0. 1. 0. 4. 2. 6. 0. 3.\n",
      " 3. 4. 1. 0. 4. 2. 4. 4. 0. 1. 0. 0. 1. 0. 4.]\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder()\n",
    "encoder.fit(Y)\n",
    "encoded_y = encoder.transform(Y)\n",
    "print(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.43002312e-14, -1.25127023e-15, -1.69815245e-15, -1.25127023e-15,\n",
       "        2.68129334e-16,  4.58054279e-16])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw = X - np.mean(X, axis=0)\n",
    "qw\n",
    "np.mean(qw, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling - Normalization\n",
    "\n",
    "* test fraction - percentage of test data\n",
    "* xte - test data\n",
    "* xtr - training data\n",
    "\n",
    "xtr ->\n",
    "* mean = 0\n",
    "* standard deviation = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, x,y,test_fraction=0.05):\n",
    "        test_samples = int(test_fraction * y.size)\n",
    "        self.xte = x[:test_samples,:]   \n",
    "        self.xtr = x[test_samples:,:]   \n",
    "        self.yte = y[:test_samples]   \n",
    "        self.ytr = y[test_samples:]\n",
    "        self.mean = np.mean(self.xtr, axis=0)\n",
    "        self.std = np.std(self.xtr, axis=0)#standard deviation\n",
    "        self.xtr = self.normalize(self.xtr)\n",
    "        self.xte = self.normalize(self.xte)\n",
    "\n",
    "    def normalize(self, x):\n",
    "        x_temp = (x - self.mean)/self.std\n",
    "        return x_temp\n",
    "        \n",
    "fish_ds = Dataset(X,encoded_y,0.15)\n",
    "# fish_ds.xte \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(fish_ds.yte)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers models\n",
    "\n",
    "* KNN - K - Nearest Neighbors Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classfier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, xtr, ytr):\n",
    "        pass\n",
    "    def predict(self, x):\n",
    "        pass\n",
    "    def evaluate(self, xte, yte):\n",
    "        ypred = self.predict(xte)\n",
    "        print(yte.astype(int))\n",
    "        print(ypred)\n",
    "        acc = np.sum(ypred == yte) / yte.size #Accuracy\n",
    "        return acc\n",
    "\n",
    "# Baseline (method)\n",
    "class RandomClassifier(Classfier):\n",
    "    #expected accuracy = 1/7\n",
    "    def fit(self, xtr, ytr):\n",
    "        self.num_classes = int(np.max(ytr) + 1)\n",
    "    def predict(self, x):\n",
    "        return np.random.choice(self.num_classes, x.shape[0])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 2 2 0 0 0 1 2 3 1 2 0 4 4 0 1 0 0 2]\n",
      "[4 6 4 5 3 6 5 0 5 4 0 6 2 4 0 4 3 2 0 1 3 4 0]\n",
      "0.13043478260869565\n"
     ]
    }
   ],
   "source": [
    "random_classifier = RandomClassifier()\n",
    "random_classifier.fit(fish_ds.xtr, fish_ds.ytr)\n",
    "randow_acc = random_classifier.evaluate(fish_ds.xte, fish_ds.yte)\n",
    "print(randow_acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5d8d3d050c10ab3dcb6699cc248e53317db60ba2858504a06e019b80fca7572"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
