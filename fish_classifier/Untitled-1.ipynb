{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fish classifier\n",
    "\n",
    "Author: Åukasz Szarecki \n",
    "\n",
    "Dataset: https://www.kaggle.com/aungpyaeap/fish-market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Uploading data to pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Species  Weight  Length1  Length2  Length3   Height   Width\n",
      "0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
      "1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
      "2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
      "3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
      "4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "fish_df = pd.read_csv(\"Fish.csv\")\n",
    "print(fish_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We have to mix data because there are sorted.\n",
    "3. Preapering training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Species  Weight  Length1  Length2  Length3   Height   Width\n",
      "0      Perch  1015.0     37.0     40.0     42.4  12.3808  7.4624\n",
      "1      Perch   150.0     20.5     22.5     24.0   6.7920  3.6240\n",
      "2      Bream   700.0     31.9     35.0     40.5  16.2405  5.5890\n",
      "3      Roach   140.0     21.0     22.5     25.0   6.5500  3.3250\n",
      "4  Whitefish   270.0     24.1     26.5     29.3   8.1454  4.2485\n",
      "There are 159 samples\n"
     ]
    }
   ],
   "source": [
    "#sorting dataset\n",
    "fish_df = fish_df.sample(frac=1)\n",
    "#corect indexing\n",
    "fish_df = fish_df.reset_index(drop=True)\n",
    "print(fish_df.head())\n",
    "print(f'There are {len(fish_df)} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Input and output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 6)\n",
      "(159,)\n"
     ]
    }
   ],
   "source": [
    "#input\n",
    "X = np.array(fish_df.iloc[:, 1::])\n",
    "print(X.shape)\n",
    "#output\n",
    "Y = (fish_df.iloc[:,0])\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder class\n",
    "\n",
    "3. Each fish will have its own identifier\n",
    "* fit() - create connection between identifiers and fish names\n",
    "* transform() - fish name (str) to id (int)\n",
    "* inverse_transform() - id (int) to fish name (str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder():\n",
    "    def __init__(self):\n",
    "        self.names = [] #to not store duplicated names\n",
    "        self.num_classes = 0 #number of all classes\n",
    "    def fit(self, y):\n",
    "        for sample in y:\n",
    "            if sample not in self.names:\n",
    "                self.names.append(sample)\n",
    "        self.num_classes = len(self.names)\n",
    "    def transform(self, y):\n",
    "        encoded_samples = np.zeros(len(y))\n",
    "        for index,sample in enumerate(y):\n",
    "            encoded_samples[index] = self.names.index(sample)\n",
    "        return encoded_samples\n",
    "    def inverse_transform(self, encoded_y):\n",
    "        samples = []\n",
    "        for sample in encoded_y:\n",
    "            samples.append(self.names[int(sample)])\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Perch', 'Bream', 'Roach', 'Whitefish', 'Parkki', 'Smelt', 'Pike']\n",
      "7\n",
      "['Pike', 'Smelt', 'Perch', 'Pike', 'Pike', 'Bream', 'Bream', 'Roach']\n"
     ]
    }
   ],
   "source": [
    "#tests\n",
    "encoder = Encoder()\n",
    "encoder.fit(Y)\n",
    "print(encoder.names)\n",
    "print(encoder.num_classes) \n",
    "\n",
    "test_list = ['Pike', 'Smelt', 'Perch', 'Pike', 'Pike', 'Bream', 'Bream', 'Roach']\n",
    "encoded_num_test = encoder.transform(test_list)\n",
    "print(encoder.inverse_transform(encoded_num_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Encoding dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 2. 3. 0. 1. 0. 4. 0. 4. 4. 4. 4. 1. 4. 0. 0. 5. 0. 4. 1. 6. 1.\n",
      " 6. 0. 1. 6. 1. 6. 5. 0. 5. 0. 0. 1. 2. 1. 6. 0. 0. 2. 2. 0. 2. 1. 6. 0.\n",
      " 3. 0. 2. 0. 4. 0. 1. 0. 2. 0. 1. 2. 1. 5. 6. 2. 0. 0. 5. 5. 0. 2. 6. 0.\n",
      " 0. 6. 0. 1. 0. 6. 0. 0. 0. 1. 2. 4. 2. 5. 0. 5. 0. 1. 6. 1. 2. 5. 5. 1.\n",
      " 1. 1. 0. 1. 1. 3. 1. 0. 0. 5. 6. 1. 1. 3. 0. 1. 5. 0. 1. 3. 0. 0. 1. 0.\n",
      " 2. 0. 1. 0. 2. 1. 6. 0. 0. 5. 0. 2. 0. 0. 6. 4. 0. 2. 6. 1. 0. 1. 6. 0.\n",
      " 6. 2. 5. 0. 1. 0. 0. 1. 0. 4. 0. 2. 2. 3. 1.]\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder()\n",
    "encoder.fit(Y)\n",
    "encoded_y = encoder.transform(Y)\n",
    "print(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.28702080e-14,  6.03291002e-15, -1.60877601e-15, -1.02782911e-15,\n",
       "        2.79301390e-16,  4.35710168e-16])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw = X - np.mean(X, axis=0)\n",
    "qw\n",
    "np.mean(qw, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling - Normalization\n",
    "\n",
    "* test fraction - percentage of test data\n",
    "* xte - test data\n",
    "* xtr - training data\n",
    "\n",
    "xtr ->\n",
    "* mean = 0\n",
    "* standard deviation = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x,y,test_fraction=0.05):\n",
    "        test_samples = int(test_fraction * y.size)\n",
    "        self.xte = x[:test_samples,:]   \n",
    "        self.xtr = x[test_samples:,:]   \n",
    "        self.yte = y[:test_samples]   \n",
    "        self.ytr = y[test_samples:]\n",
    "        self.mean = np.mean(self.xtr, axis=0)\n",
    "        self.std = np.std(self.xtr, axis=0)#standard deviation\n",
    "        self.xtr = self.normalize(self.xtr)\n",
    "        self.xte = self.normalize(self.xte)\n",
    "\n",
    "    def normalize(self, x):\n",
    "        x_temp = (x - self.mean)/self.std\n",
    "        return x_temp\n",
    "        \n",
    "fish_ds = Dataset(X,Y,0.15)\n",
    "# fish_ds.xte \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN - K - Nearest Neighbors Algorithm\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5d8d3d050c10ab3dcb6699cc248e53317db60ba2858504a06e019b80fca7572"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
